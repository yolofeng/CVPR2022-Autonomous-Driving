# CVPR 2022 |自动驾驶 |资源合集(Papers with Code)

> 
>
> 知乎 ：https://zhuanlan.zhihu.com/p/532823137
>
> 

[TOC]



## 自动驾驶数据集

CVPR2022 |新增数据集--V2X(首个) | DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection| [[论文链接](https://arxiv.org/pdf/2204.05575v1.pdf)] [[项目主页](https://thudair.baai.ac.cn/index)][解读链接]

CVPR2022 |新增数据集-仿真环境里程计数据|CarlaScenes: A synthetic dataset for odometry in autonomous driving| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Kloukiniotis_CarlaScenes_A_Synthetic_Dataset_for_Odometry_in_Autonomous_Driving_CVPRW_2022_paper.pdf)] [[代码链接](https://github.com/CarlaScenes/CarlaSence.git)][解读链接]

CVPR2022 |新增数据集-激光雷达车道线|K-Lane: Lidar Lane Dataset and Benchmark for Urban Roads and Highways| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Paek_K-Lane_Lidar_Lane_Dataset_and_Benchmark_for_Urban_Roads_and_CVPRW_2022_paper.pdf)] [[代码链接](https://github.com/kaist-avelab/k-lane)][解读链接]

CVPR2022 |新增数据集-路面湿度估计|RoadSaW: A Large-Scale Dataset for Camera-Based Road Surface and Wetness Estimation| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Cordes_RoadSaW_A_Large-Scale_Dataset_for_Camera-Based_Road_Surface_and_Wetness_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

CVPR2022 |新增数据集-环境动态变化|SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation| [[论文链接](https://arxiv.org/pdf/2206.08367.pdf)] [代码链接][解读链接]

CVPR2022 |新增数据集--密集行人多模态| STCrowd: A Multimodal Dataset for Pedestrian Perception in Crowded Scenes| [[论文链接](https://arxiv.org/pdf/2204.01026.pdf)] [[代码链接](https://github.com/4DVLab/STCrowd)][解读链接]

CVPR2022 |数据集合增强--样本生成 | Local and Global GANs with Semantic-Aware Upsampling for Image Generation [[论文链接](https://arxiv.org/pdf/2203.00047.pdf)][[代码链接](https://github.com/Ha0Tang/LGGAN)][解读链接]

## end-end自动驾驶

CVPR2022 |端到端自动驾驶|On the Choice of Data for Efficient Training and Validation of End-to-End Driving Models| [[论文链接](https://arxiv.org/pdf/2206.00608.pdf)] [代码链接][解读链接]

CVPR2022 | 端到端自动驾驶| Learning from All Vehicles| [[论文链接](https://arxiv.org/pdf/2203.11934.pdf)] [[代码链接](https://github.com/dotchen/LAV)][解读链接]

## BEV感知算法

CVPR2022 |BEV感知地图+障碍物|Cross-view Transformers for real-time Map-view Semantic Segmentation| [[论文链接](https://arxiv.org/pdf/2205.02833.pdf)] [[代码链接](https://github.com/bradyz/cross_view_transformers)][解读链接]

CVPR2022 |BEV障碍物投影| “The Pedestrian next to the Lamppost” Adaptive Object Graphs for Better Instantaneous Mapping | [[论文链接](https://arxiv.org/pdf/2204.02944.pdf)] [代码链接][解读链接]

CVPR2022 |BEV感知车道线+障碍物|Scene Representation in Bird’s-Eye View from Surrounding Cameras with Transformers| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Zhao_Scene_Representation_in_Birds-Eye_View_From_Surrounding_Cameras_With_Transformers_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

CVPR2022 |BEV尺度下-基于web数据学习驾驶策略|SelfD: Self-Learning Large-Scale Driving Policies From the Web| [[论文链接](https://arxiv.org/pdf/2204.10320.pdf)] [代码链接][解读链接]

## Corner Case(Anomaly Detection)解决方案

CVPR2022 |异常检测综述|Anomaly Detection in Autonomous Driving: A Survey| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Bogdoll_Anomaly_Detection_in_Autonomous_Driving_A_Survey_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

CVPR2022 |异常场景语义分割|Towards Robust Semantic Segmentation of Accident Scenes via Multi-Source Mixed Sampling and Meta-Learning| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Luo_Towards_Robust_Semantic_Segmentation_of_Accident_Scenes_via_Multi-Source_Mixed_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

CVPR2022 |多种天气增量学习|An Efficient Domain-Incremental Learning Approach to Drive in All Weather Conditions| [[论文链接](https://arxiv.org/pdf/2204.08817.pdf)] [代码链接][解读链接]

CVPR2022 | 极端天气3D检测-点云| LiDAR Snowfall Simulation for Robust 3D Object Detection | [[墙内论文](https://zhuanlan.zhihu.com/p/490357720)] [[代码链接](https://github.com/SysCV/LiDAR)][解读链接]

CVPR2022 |数据集增强--光照条件| SIMBAR: Single Image-Based Scene Relighting For Effective Data Augmentation For Automated Driving Vision Tasks| [[论文链接](https://arxiv.org/pdf/2204.00644.pdf)] [[代码链接](https://simbarv1.github.io/)][解读链接]

CVPR2022 |多天气数据增强| InstaFormer: Instance-Aware Image-to-Image Translation with Transformer| [[论文链接](https://arxiv.org/pdf/2203.16248.pdf)] [代码链接][解读链接]

CVPR2022 |雨雾天气处理| Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond | [[论文链接](https://zhuanlan.zhihu.com/p/490357720)] [[代码链接](https://github.com/yuyi-sd/Robust_Rain_Removal)][解读链接]

## 障碍物轨迹预测

CVPR2022 |轨迹预测--Transformer|HiVT: Hierarchical Vector Transformer for Multi-Agent Motion Prediction| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.pdf)] [[代码链接](https://github.com/ZikangZhou/HiVT)][解读链接]

CVPR2022 |点云数据-轨迹预测|PointMotionNet: Point-Wise Motion Learning for Large-Scale LiDAR Point Clouds Sequences| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Wang_PointMotionNet_Point-Wise_Motion_Learning_for_Large-Scale_LiDAR_Point_Clouds_Sequences_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

CVPR2022 |轨迹预测|Goal-driven Self-Attentive Recurrent Networks for Trajectory Prediction| [[论文链接](https://arxiv.org/pdf/2204.11561)] [[代码链接](https://link.zhihu.com/?target=http%3A//github.com/dvlab-research/FocalsConv)][解读链接]

CVPR2022 |轨迹预测|Importance is in your attention: agent importance prediction for autonomous driving| [[论文链接](https://arxiv.org/pdf/2204.09121.pdf)] [代码链接][解读链接]

CVPR2022 |轨迹预测| End-to-End Trajectory Distribution Prediction Based on Occupancy Grid Maps| [[论文链接](https://arxiv.org/pdf/2203.16910.pdf)] [[代码链接](https://github.com/Kguo-cs/TDOR)][解读链接]

CVPR2022 |轨迹预测-点云| Forecasting from LiDAR via Future Object Detection | [[论文链接](https://arxiv.org/pdf/2203.16297.pdf)] [[代码链接](https://github.com/neeharperi/FutureDet)][[解读链接](https://zhuanlan.zhihu.com/p/492028818)]

CVPR2022 | 轨迹预测-行人 | Adaptive Trajectory Prediction via Transferable GNN| [[论文链接](https://arxiv.org/pdf/2203.05046.pdf)] [代码链接][解读链接]

CVPR2022 |轨迹预测-利用上下文信息 | Raising context awareness in motion forecasting| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Ben-Younes_Raising_Context_Awareness_in_Motion_Forecasting_CVPRW_2022_paper.pdf)] [[代码链接](https://link.zhihu.com/?target=http%3A//github.com/valeoai/CAB)][解读链接]

## 建图与定位

CVPR2022 |视觉定位| Deep Visual Geo-localization Benchmark | [[论文链接](https://arxiv.org/pdf/2204.03444.pdf)] [[代码链接](https://deep-vg-bench.herokuapp.com/)][解读链接]

CVPR2022 |视觉定位| Rethinking Visual Geo-localization for Large-Scale Applications| [[论文链接](https://arxiv.org/pdf/2204.02287.pdf)] [[代码链接](https://github.com/gmberton/CosPlace)][解读链接]

CVPR2022 | 稀疏地图| Long-term Visual Map Sparsification with Heterogeneous GNN | [[论文链接](https://arxiv.org/pdf/2203.15182.pdf)] [代码链接][解读链接]

## 多模态数据融合算法

CVPR2022 |多模态数据融合--ViT|Multimodal Token Fusion for Vision Transformers| [[论文链接](https://arxiv.org/pdf/2204.08721.pdf)] [代码链接][解读链接]

CVPR2022 | 数据融合-Lidar-Camera| DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection| [[论文链接](https://arxiv.org/pdf/2203.08195.pdf)] [[代码链接](https://github.com/tensorflow/lingvo/)][解读链接]

## 多任务学习网络

CVPR2022 | 多任务学习| Task Adaptive Parameter Sharing for Multi-Task Learning | [[论文链接](https://arxiv.org/pdf/2203.16708.pdf)] [代码链接][解读链接]

CVPR2022 | 多任务网络| Controllable Dynamic Multi-Task Architectures | [[论文链接](https://arxiv.org/pdf/2203.14949.pdf)] [[代码链接](https://www.nec-labs.com/%CB%9Cmas/DYMU)][解读链接]

## 2d/3d目标检测算法

CVPR2022 |3d目标检测--点云|Focal Sparse Convolutional Networks for 3D Object Detection| [[论文链接](https://arxiv.org/pdf/2204.12463.pdf)] [[代码链接](https://paperswithcode.com/search%3Fq_meta%3D%26q_type%3D%26q%3DFocal%2BSparse%2BConvolutional%2BNetworks%2Bfor%2B3D%2BObject%2BDetection)][解读链接]

CVPR2022 |3d目标检测--点云| OccAM’s Laser: Occlusion-based Attribution Maps for 3D Object Detectors on LiDAR Data| [[论文链接](https://arxiv.org/pdf/2204.06577.pdf)] [代码链接][解读链接]

CVPR2022 |3d目标检测-图像| AutoRF: Learning 3D Object Radiance Fields from Single View Observations | [[论文链接](https://arxiv.org/pdf/2204.03593.pdf)] [[代码链接](https://sirwyver.github.io/AutoRF/)][解读链接]

CVPR2022 |粗标注目标检测| Towards Robust Adaptive Object Detection under Noisy Annotations| [[论文链接](https://arxiv.org/pdf/2204.02620.pdf)] [代码链接][解读链接]

CVPR2022 |目标检测--毫米波雷达| Exploiting Temporal Relations on Radar Perception for Autonomous Driving| [[论文链接](https://arxiv.org/pdf/2204.01184.pdf)] [代码链接][解读链接]

CVPR2022 |3d目标检测-图像| Homography Loss for Monocular 3D Object Detection| [[论文链接](https://arxiv.org/pdf/2204.00754.pdf)] [代码链接][解读链接]

CVPR2022 |3d目标检测--图像+点云| CAT-Det: Contrastively Augmented Transformer for Multi-modal 3D Object Detection| [[论文链接](https://arxiv.org/pdf/2204.00325.pdf)] [代码链接][解读链接]

CVPR2022 |2d目标检测| AdaMixer: A Fast-Converging Query-Based Object Detector | [[论文链接](https://arxiv.org/pdf/2203.16507.pdf)] [代码链接][解读链接]

CVPR2022 | 目标检测| Multi-Granularity Alignment Domain Adaptation for Object Detection | [[论文链接](https://arxiv.org/pdf/2203.16897.pdf)] [[代码链接](https://github.com/tiankongzhang/MGADA)][解读链接]

CVPR2022 | 3D目标检测-图像| MonoDETR: Depth-aware Transformer for Monocular 3D Object Detection | [[论文链接](https://arxiv.org/pdf/2203.13310.pdf)] [[代码链接](https://github.com/ZrrSkywalker/MonoDETR.git)][解读链接]

CVPR2022 | 2D目标检测-视频流| Real-time Object Detection for Streaming Perception | [[论文链接](https://arxiv.org/pdf/2203.12338.pdf)] [[代码链接](https://github.com/yancie-yjr/StreamYOLO)][解读链接]

CVPR2022 | 3D目标检测-图像+点云| Sparse Fuse Dense: Towards High Quality 3D Detection with Depth Completion | [[论文链接](https://arxiv.org/pdf/2203.09780.pdf)] [代码链接][解读链接]

CVPR2022 | 3D目标检测-图像| MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer | [[论文链接](https://arxiv.org/pdf/2203.10981.pdf)] [[代码链接](https://link.zhihu.com/?target=http%3A//github.com/kuanchihhuang/MonoDTR)][解读链接]

CVPR2022 | 3D目标检测-图像| MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection| [[论文链接](https://arxiv.org/pdf/2203.08563.pdf)] [[代码链接](https://github.com/lianqing11/MonoJSG)][解读链接]

CVPR2022 | 目标检测-点云 | Point Density-Aware Voxels for LiDAR 3D Object Detection| [[论文链接](https://arxiv.org/pdf/2203.05662.pdf)] [[代码链接](https://github.com/TRAILab/PDV)][解读链接]

CVPR2022 | 交通标志识别| Shadows can be Dangerous: Stealthy and Effective Physical-world Adversarial Attack by Natural Phenomenon [[论文链接](https://arxiv.org/pdf/2203.03818.pdf)] [代码链接][解读链接]

CVPR2022 | 点云目标检测| A Unified Query-based Paradigm for Point Cloud Understanding [[墙内论文链接](https://zhuanlan.zhihu.com/p/490340652)] [代码链接][[解读链接](https://zhuanlan.zhihu.com/p/475447903)]

CVPR2022 | 目标检测-点云| A Versatile Multi-View Framework for LiDAR-based 3D Object Detection with Guidance from Panoptic Segmentation. [[论文链接](https://arxiv.org/pdf/2203.02133.pdf)] [代码链接][解读链接]

CVPR2022 | 3d目标检测-图像 | Pseudo-Stereo for Monocular 3D Object Detection in Autonomous Driving. [[论文链接](https://arxiv.org/pdf/2203.02112.pdf)] [[代码链接](https://github.com/revisitq/Pseudo-Stereo-3D)][解读链接]

CVPR2022|目标检测-点云| Embracing Single Stride 3D Object Detector with Sparse Transformer[[论文链接](https://arxiv.org/pdf/2112.06375.pdf)][[代码链接](https://github.com/TuSimple/SST)][[解读链接](https://zhuanlan.zhihu.com/p/475885444)]

CVPR2022 |目标检测-半监督| PseudoProp: Robust Pseudo-Label Generation for Semi-Supervised Object Detection in Autonomous Driving Systems[[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Hu_PseudoProp_Robust_Pseudo-Label_Generation_for_Semi-Supervised_Object_Detection_in_Autonomous_CVPRW_2022_paper.pdf)][代码链接][解读链接]

## 多目标跟踪算法

CVPR2022 |目标检测-多相机|MUTR3D: A Multi-camera Tracking Framework via 3D-to-2D Queries| [[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Zhang_MUTR3D_A_Multi-Camera_Tracking_Framework_via_3D-to-2D_Queries_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

CVPR2022 |目标检测/跟踪-端到端|Time3D: End-to-End Joint Monocular 3D Object Detection and Tracking for Autonomous Driving| [[论文链接](https://arxiv.org/pdf/2205.14882.pdf)] [代码链接][解读链接]

CVPR2022 |行人重识别| Cloning Outfits from Real-World Images to 3D Characters for Generalizable Person Re-Identification| [[论文链接](https://arxiv.org/pdf/2204.02611.pdf)] [[代码链接](https://github.com/Yanan-Wang-cs/ClonedPerson)][解读链接]

CVPR2022 | 多目标跟踪-图像| MeMOT: Multi-Object Tracking with Memory | [[论文链接](https://arxiv.org/pdf/2203.16761.pdf)] [代码链接][解读链接]

CVPR2022 | 目标跟踪 | Unified Transformer Tracker for Object Tracking | [[论文链接](https://arxiv.org/pdf/2203.15182.pdf)] [代码链接][解读链接]

CVPR2022|目标跟踪-点云| Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds[[论文链接](https://arxiv.org/pdf/2203.01730v1.pdf)][[代码链接](https://github.com/Ghostish/Open3DSOT)][解读链接]

CVPR2022 | 目标跟踪-LSTM| TripletTrack: 3D Object Tracking using Triplet Embeddings and LSTM[[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Marinello_TripletTrack_3D_Object_Tracking_Using_Triplet_Embeddings_and_LSTM_CVPRW_2022_paper.pdf)][代码链接][解读链接]

## 场景分割算法

CVPR2022 |全景分割| Joint Forecasting of Panoptic Segmentations with Difference Attention| [[论文链接](https://arxiv.org/pdf/2204.07157.pdf)] [代码链接][解读链接]

CVPR2022 |夜间语义分割| NightLab: A Dual-level Architecture with Hardness Detection for Segmentation at Night| [[论文链接](https://arxiv.org/pdf/2204.05538.pdf)] [[代码链接](https://github.com/xdeng7/NightLab)][解读链接]

CVPR2022 |全景分割| Panoptic, Instance and Semantic Relations: A Relational Context Encoder to Enhance Panoptic Segmentation| [[论文链接](https://arxiv.org/pdf/2204.05370.pdf)] [代码链接][解读链接]

CVPR2022 |目标检测分割--自监督| Image-to-Lidar Self-Supervised Distillation for Autonomous Driving Data| [[论文链接](https://arxiv.org/pdf/2203.16258.pdf)] [[代码链接](https://github.com/valeoai/SLidR)][解读链接]

CVPR2022 |语义分割-图像| Pin the Memory: Learning to Generalize Semantic Segmentation | [[论文链接](https://arxiv.org/pdf/2204.03609.pdf)] [代码链接][解读链接]

CVPR2022 | 点云分割-弱监督| Scribble-Supervised LiDAR Semantic Segmentation| [[论文链接](https://arxiv.org/pdf/2203.08537.pdf)] [[代码链接](https://github.com/tensorflow/lingvo/)][解读链接]

CVPR2022 | 实例分割 | E2EC: An End-to-End Contour-based Method for High-Quality High-Speed Instance Segmentation| [[论文链接](https://arxiv.org/pdf/2203.04074.pdf)] [[代码链接](https://github.com/zhang-tao-whu/e2ec)][[解读链接](https://zhuanlan.zhihu.com/p/478984784?utm_medium=social&utm_oi=790318501125591040)]

CVPR2022| 全景分割| Bending Reality: Distortion-aware Transformers for Adapting to Panoramic Semantic Segmentation[[论文链接](https://arxiv.org/pdf/2203.01452.pdf)][[代码链接](https://github.com/jamycheung/Trans4PASS)][解读链接]

CVPR2022 |激光雷达数据-全景分割| Proposal-free Lidar Panoptic Segmentation with Pillar-level Affinity[[论文链接](https://arxiv.org/pdf/2204.08744.pdf)][代码链接][解读链接]

CVPR2022 |语义分割-图像-自监督| Performance Prediction for Semantic Segmentation by a Self-Supervised Image Reconstruction Decoder[[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Bar_Performance_Prediction_for_Semantic_Segmentation_by_a_Self-Supervised_Image_Reconstruction_CVPRW_2022_paper.pdf)][代码链接][解读链接]

## 车道线/可行驶区域

CVPR2022 |车道线检测|ONCE-3DLanes: Building Monocular 3D Lane Detection| [[论文链接](https://arxiv.org/pdf/2205.00301.pdf)] [[代码链接](https://once-3dlanes.github.io/)][解读链接]

CVPR2022 | 车道线检测| Towards Driving-Oriented Metric for Lane Detection Models | [[论文链接](https://arxiv.org/pdf/2203.16851.pdf)] [[代码链接](https://github.com/leolyj/DCA-SRSFE)][解读链接]

CVPR2022 | 车道线检测 | Rethinking Efficient Lane Detection via Curve Modeling. [[论文链接](https://arxiv.org/pdf/2203.02431.pdf)] [[代码链接](https://github.com/voldemortX/pytorch-auto-drive)][解读链接]

CVPR2022 |顶视图车道线检测 | Reconstruct from Top View: A 3D Lane Detection Approach based on Geometry Structure Prior[[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Li_Reconstruct_From_Top_View_A_3D_Lane_Detection_Approach_Based_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

CVPR2022 |多数据集融合-车道线检测 |Multi-level Domain Adaptation for Lane Detection[[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Li_Multi-Level_Domain_Adaptation_for_Lane_Detection_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

## 深度估计

CVPR2022 |360度深度估计| HiMODE: A Hybrid Monocular Omnidirectional Depth Estimation Model| [[论文链接](https://arxiv.org/pdf/2204.05007.pdf)] [代码链接][解读链接]

CVPR2022 |深度估计| P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior| [[论文链接](https://arxiv.org/pdf/2204.02091.pdf)] [[代码链接](https://github.com/SysCV/P3Depth)][解读链接]

CVPR2022 |深度估计 | NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth Estimation. [[论文链接](https://arxiv.org/pdf/2203.01502.pdf)] [代码链接][解读链接]

CVPR2022 |无监督-深度估计 | H-Net: Unsupervised Attention-based Stereo Depth Estimation Leveraging Epipolar Geometry[[论文链接](https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Huang_H-Net_Unsupervised_Attention-Based_Stereo_Depth_Estimation_Leveraging_Epipolar_Geometry_CVPRW_2022_paper.pdf)] [代码链接][解读链接]

## 其他

CVPR2022 | 车流量估计| Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds | [[论文链接](https://arxiv.org/pdf/2203.16895.pdf)] [[代码链接](https://github.com/leolyj/DCA-SRSFE)][解读链接]

CVPR2022 | 目标姿态估计| EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation | [[论文链接](https://arxiv.org/pdf/2203.13254.pdf)] [[代码链接](https://github.com/tjiiv-cprg/EPro-PnP)][解读链接]

CVPR2022 | 相机姿态估计| DiffPoseNet: Direct Differentiable Camera Pose Estimation | [[论文链接](https://arxiv.org/pdf/2203.11174.pdf)] [代码链接][解读链接]

CVPR2022 |神经网络可解释性| Interpretable part-whole hierarchies and conceptual-semantic relationships in neural networks. [[论文链接](https://arxiv.org/pdf/2203.03282v1.pdf)] [[代码链接](https://github.com/mmlab-cv/Agglomerator)][解读链接]









